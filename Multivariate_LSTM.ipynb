{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multivariate_LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4u8R53qxIwvJ"
      },
      "source": [
        "# Stock Price Prediction using Multiivariate LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVTNFFkeI8xR"
      },
      "source": [
        "This notebook showcases how to predict the closing price of a stock using a multiple features. The model used is **Bidirectional LSTM** which is a type of RNN. The data used is downloaded from the NSE website for the NIFTY-50 companies. The model looks back at 100 days of previous data and gives a prediction for the next day.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkmG5Mf-NCzI",
        "outputId": "c9dbc25c-3c3d-4b89-a89b-0434e3657949"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5XjcG8fMHe8"
      },
      "source": [
        "import numpy as np\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import LSTM\r\n",
        "from keras.layers import Dense, Dropout, RepeatVector\r\n",
        "import pandas as pd\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\r\n",
        "import seaborn as sns\r\n",
        "#from datetime import datetime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "e5oaQ3PRNDgp",
        "outputId": "71eb7767-02be-4d50-e5ea-7a74901524e0"
      },
      "source": [
        "df = pd.read_csv(\"/content/^NSEI (2).csv\")\r\n",
        "df\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>21-01-2013</td>\n",
              "      <td>6085.750000</td>\n",
              "      <td>6094.350098</td>\n",
              "      <td>6065.100098</td>\n",
              "      <td>6082.299805</td>\n",
              "      <td>6082.299805</td>\n",
              "      <td>130900.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>22-01-2013</td>\n",
              "      <td>6080.149902</td>\n",
              "      <td>6101.299805</td>\n",
              "      <td>6040.500000</td>\n",
              "      <td>6048.500000</td>\n",
              "      <td>6048.500000</td>\n",
              "      <td>129000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>23-01-2013</td>\n",
              "      <td>6052.850098</td>\n",
              "      <td>6069.799805</td>\n",
              "      <td>6021.149902</td>\n",
              "      <td>6054.299805</td>\n",
              "      <td>6054.299805</td>\n",
              "      <td>137000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>24-01-2013</td>\n",
              "      <td>6046.200195</td>\n",
              "      <td>6065.299805</td>\n",
              "      <td>6007.850098</td>\n",
              "      <td>6019.350098</td>\n",
              "      <td>6019.350098</td>\n",
              "      <td>185200.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>25-01-2013</td>\n",
              "      <td>6024.500000</td>\n",
              "      <td>6080.549805</td>\n",
              "      <td>6014.450195</td>\n",
              "      <td>6074.649902</td>\n",
              "      <td>6074.649902</td>\n",
              "      <td>147600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1978</th>\n",
              "      <td>28-01-2021</td>\n",
              "      <td>13810.400390</td>\n",
              "      <td>13898.250000</td>\n",
              "      <td>13713.250000</td>\n",
              "      <td>13817.549810</td>\n",
              "      <td>13817.549810</td>\n",
              "      <td>637900.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1979</th>\n",
              "      <td>29-01-2021</td>\n",
              "      <td>13946.599610</td>\n",
              "      <td>13966.849610</td>\n",
              "      <td>13596.750000</td>\n",
              "      <td>13634.599610</td>\n",
              "      <td>13634.599610</td>\n",
              "      <td>753200.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1980</th>\n",
              "      <td>01-02-2021</td>\n",
              "      <td>13758.599610</td>\n",
              "      <td>14336.349610</td>\n",
              "      <td>13661.750000</td>\n",
              "      <td>14281.200200</td>\n",
              "      <td>14281.200200</td>\n",
              "      <td>870500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1981</th>\n",
              "      <td>02-02-2021</td>\n",
              "      <td>14481.099610</td>\n",
              "      <td>14731.700200</td>\n",
              "      <td>14469.150390</td>\n",
              "      <td>14647.849610</td>\n",
              "      <td>14647.849610</td>\n",
              "      <td>915000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1982</th>\n",
              "      <td>03-02-2021</td>\n",
              "      <td>14754.900390</td>\n",
              "      <td>14868.849610</td>\n",
              "      <td>14574.150390</td>\n",
              "      <td>14789.950200</td>\n",
              "      <td>14789.950200</td>\n",
              "      <td>869500.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1983 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Date          Open  ...     Adj Close    Volume\n",
              "0     21-01-2013   6085.750000  ...   6082.299805  130900.0\n",
              "1     22-01-2013   6080.149902  ...   6048.500000  129000.0\n",
              "2     23-01-2013   6052.850098  ...   6054.299805  137000.0\n",
              "3     24-01-2013   6046.200195  ...   6019.350098  185200.0\n",
              "4     25-01-2013   6024.500000  ...   6074.649902  147600.0\n",
              "...          ...           ...  ...           ...       ...\n",
              "1978  28-01-2021  13810.400390  ...  13817.549810  637900.0\n",
              "1979  29-01-2021  13946.599610  ...  13634.599610  753200.0\n",
              "1980  01-02-2021  13758.599610  ...  14281.200200  870500.0\n",
              "1981  02-02-2021  14481.099610  ...  14647.849610  915000.0\n",
              "1982  03-02-2021  14754.900390  ...  14789.950200  869500.0\n",
              "\n",
              "[1983 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "6J6iaflTzMxN",
        "outputId": "29703a97-689f-4fab-b285-fc81833e5134"
      },
      "source": [
        "#df = df.reindex(index=df.index[::-1])\r\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>21-01-2013</td>\n",
              "      <td>6085.750000</td>\n",
              "      <td>6094.350098</td>\n",
              "      <td>6065.100098</td>\n",
              "      <td>6082.299805</td>\n",
              "      <td>6082.299805</td>\n",
              "      <td>130900.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>22-01-2013</td>\n",
              "      <td>6080.149902</td>\n",
              "      <td>6101.299805</td>\n",
              "      <td>6040.500000</td>\n",
              "      <td>6048.500000</td>\n",
              "      <td>6048.500000</td>\n",
              "      <td>129000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>23-01-2013</td>\n",
              "      <td>6052.850098</td>\n",
              "      <td>6069.799805</td>\n",
              "      <td>6021.149902</td>\n",
              "      <td>6054.299805</td>\n",
              "      <td>6054.299805</td>\n",
              "      <td>137000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>24-01-2013</td>\n",
              "      <td>6046.200195</td>\n",
              "      <td>6065.299805</td>\n",
              "      <td>6007.850098</td>\n",
              "      <td>6019.350098</td>\n",
              "      <td>6019.350098</td>\n",
              "      <td>185200.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>25-01-2013</td>\n",
              "      <td>6024.500000</td>\n",
              "      <td>6080.549805</td>\n",
              "      <td>6014.450195</td>\n",
              "      <td>6074.649902</td>\n",
              "      <td>6074.649902</td>\n",
              "      <td>147600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1978</th>\n",
              "      <td>28-01-2021</td>\n",
              "      <td>13810.400390</td>\n",
              "      <td>13898.250000</td>\n",
              "      <td>13713.250000</td>\n",
              "      <td>13817.549810</td>\n",
              "      <td>13817.549810</td>\n",
              "      <td>637900.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1979</th>\n",
              "      <td>29-01-2021</td>\n",
              "      <td>13946.599610</td>\n",
              "      <td>13966.849610</td>\n",
              "      <td>13596.750000</td>\n",
              "      <td>13634.599610</td>\n",
              "      <td>13634.599610</td>\n",
              "      <td>753200.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1980</th>\n",
              "      <td>01-02-2021</td>\n",
              "      <td>13758.599610</td>\n",
              "      <td>14336.349610</td>\n",
              "      <td>13661.750000</td>\n",
              "      <td>14281.200200</td>\n",
              "      <td>14281.200200</td>\n",
              "      <td>870500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1981</th>\n",
              "      <td>02-02-2021</td>\n",
              "      <td>14481.099610</td>\n",
              "      <td>14731.700200</td>\n",
              "      <td>14469.150390</td>\n",
              "      <td>14647.849610</td>\n",
              "      <td>14647.849610</td>\n",
              "      <td>915000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1982</th>\n",
              "      <td>03-02-2021</td>\n",
              "      <td>14754.900390</td>\n",
              "      <td>14868.849610</td>\n",
              "      <td>14574.150390</td>\n",
              "      <td>14789.950200</td>\n",
              "      <td>14789.950200</td>\n",
              "      <td>869500.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1983 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Date          Open  ...     Adj Close    Volume\n",
              "0     21-01-2013   6085.750000  ...   6082.299805  130900.0\n",
              "1     22-01-2013   6080.149902  ...   6048.500000  129000.0\n",
              "2     23-01-2013   6052.850098  ...   6054.299805  137000.0\n",
              "3     24-01-2013   6046.200195  ...   6019.350098  185200.0\n",
              "4     25-01-2013   6024.500000  ...   6074.649902  147600.0\n",
              "...          ...           ...  ...           ...       ...\n",
              "1978  28-01-2021  13810.400390  ...  13817.549810  637900.0\n",
              "1979  29-01-2021  13946.599610  ...  13634.599610  753200.0\n",
              "1980  01-02-2021  13758.599610  ...  14281.200200  870500.0\n",
              "1981  02-02-2021  14481.099610  ...  14647.849610  915000.0\n",
              "1982  03-02-2021  14754.900390  ...  14789.950200  869500.0\n",
              "\n",
              "[1983 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "fxmWSoYGNYwk",
        "outputId": "a9716a41-a804-43ae-816f-989475c183b7"
      },
      "source": [
        "train_dates=pd.to_datetime(df['Date'])\r\n",
        "df=df.drop([\"Adj Close\"],axis=1)\r\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>21-01-2013</td>\n",
              "      <td>6085.750000</td>\n",
              "      <td>6094.350098</td>\n",
              "      <td>6065.100098</td>\n",
              "      <td>6082.299805</td>\n",
              "      <td>130900.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>22-01-2013</td>\n",
              "      <td>6080.149902</td>\n",
              "      <td>6101.299805</td>\n",
              "      <td>6040.500000</td>\n",
              "      <td>6048.500000</td>\n",
              "      <td>129000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>23-01-2013</td>\n",
              "      <td>6052.850098</td>\n",
              "      <td>6069.799805</td>\n",
              "      <td>6021.149902</td>\n",
              "      <td>6054.299805</td>\n",
              "      <td>137000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>24-01-2013</td>\n",
              "      <td>6046.200195</td>\n",
              "      <td>6065.299805</td>\n",
              "      <td>6007.850098</td>\n",
              "      <td>6019.350098</td>\n",
              "      <td>185200.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>25-01-2013</td>\n",
              "      <td>6024.500000</td>\n",
              "      <td>6080.549805</td>\n",
              "      <td>6014.450195</td>\n",
              "      <td>6074.649902</td>\n",
              "      <td>147600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1978</th>\n",
              "      <td>28-01-2021</td>\n",
              "      <td>13810.400390</td>\n",
              "      <td>13898.250000</td>\n",
              "      <td>13713.250000</td>\n",
              "      <td>13817.549810</td>\n",
              "      <td>637900.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1979</th>\n",
              "      <td>29-01-2021</td>\n",
              "      <td>13946.599610</td>\n",
              "      <td>13966.849610</td>\n",
              "      <td>13596.750000</td>\n",
              "      <td>13634.599610</td>\n",
              "      <td>753200.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1980</th>\n",
              "      <td>01-02-2021</td>\n",
              "      <td>13758.599610</td>\n",
              "      <td>14336.349610</td>\n",
              "      <td>13661.750000</td>\n",
              "      <td>14281.200200</td>\n",
              "      <td>870500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1981</th>\n",
              "      <td>02-02-2021</td>\n",
              "      <td>14481.099610</td>\n",
              "      <td>14731.700200</td>\n",
              "      <td>14469.150390</td>\n",
              "      <td>14647.849610</td>\n",
              "      <td>915000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1982</th>\n",
              "      <td>03-02-2021</td>\n",
              "      <td>14754.900390</td>\n",
              "      <td>14868.849610</td>\n",
              "      <td>14574.150390</td>\n",
              "      <td>14789.950200</td>\n",
              "      <td>869500.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1983 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Date          Open  ...         Close    Volume\n",
              "0     21-01-2013   6085.750000  ...   6082.299805  130900.0\n",
              "1     22-01-2013   6080.149902  ...   6048.500000  129000.0\n",
              "2     23-01-2013   6052.850098  ...   6054.299805  137000.0\n",
              "3     24-01-2013   6046.200195  ...   6019.350098  185200.0\n",
              "4     25-01-2013   6024.500000  ...   6074.649902  147600.0\n",
              "...          ...           ...  ...           ...       ...\n",
              "1978  28-01-2021  13810.400390  ...  13817.549810  637900.0\n",
              "1979  29-01-2021  13946.599610  ...  13634.599610  753200.0\n",
              "1980  01-02-2021  13758.599610  ...  14281.200200  870500.0\n",
              "1981  02-02-2021  14481.099610  ...  14647.849610  915000.0\n",
              "1982  03-02-2021  14754.900390  ...  14789.950200  869500.0\n",
              "\n",
              "[1983 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "2zSO-CA-gXKT",
        "outputId": "943f0e55-85f6-4d04-9d6f-580b43691d58"
      },
      "source": [
        "df['close'] = df['Close']\n",
        "df = df.drop('Close', axis=1)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Volume</th>\n",
              "      <th>close</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>21-01-2013</td>\n",
              "      <td>6085.750000</td>\n",
              "      <td>6094.350098</td>\n",
              "      <td>6065.100098</td>\n",
              "      <td>130900.0</td>\n",
              "      <td>6082.299805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>22-01-2013</td>\n",
              "      <td>6080.149902</td>\n",
              "      <td>6101.299805</td>\n",
              "      <td>6040.500000</td>\n",
              "      <td>129000.0</td>\n",
              "      <td>6048.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>23-01-2013</td>\n",
              "      <td>6052.850098</td>\n",
              "      <td>6069.799805</td>\n",
              "      <td>6021.149902</td>\n",
              "      <td>137000.0</td>\n",
              "      <td>6054.299805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>24-01-2013</td>\n",
              "      <td>6046.200195</td>\n",
              "      <td>6065.299805</td>\n",
              "      <td>6007.850098</td>\n",
              "      <td>185200.0</td>\n",
              "      <td>6019.350098</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>25-01-2013</td>\n",
              "      <td>6024.500000</td>\n",
              "      <td>6080.549805</td>\n",
              "      <td>6014.450195</td>\n",
              "      <td>147600.0</td>\n",
              "      <td>6074.649902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1978</th>\n",
              "      <td>28-01-2021</td>\n",
              "      <td>13810.400390</td>\n",
              "      <td>13898.250000</td>\n",
              "      <td>13713.250000</td>\n",
              "      <td>637900.0</td>\n",
              "      <td>13817.549810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1979</th>\n",
              "      <td>29-01-2021</td>\n",
              "      <td>13946.599610</td>\n",
              "      <td>13966.849610</td>\n",
              "      <td>13596.750000</td>\n",
              "      <td>753200.0</td>\n",
              "      <td>13634.599610</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1980</th>\n",
              "      <td>01-02-2021</td>\n",
              "      <td>13758.599610</td>\n",
              "      <td>14336.349610</td>\n",
              "      <td>13661.750000</td>\n",
              "      <td>870500.0</td>\n",
              "      <td>14281.200200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1981</th>\n",
              "      <td>02-02-2021</td>\n",
              "      <td>14481.099610</td>\n",
              "      <td>14731.700200</td>\n",
              "      <td>14469.150390</td>\n",
              "      <td>915000.0</td>\n",
              "      <td>14647.849610</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1982</th>\n",
              "      <td>03-02-2021</td>\n",
              "      <td>14754.900390</td>\n",
              "      <td>14868.849610</td>\n",
              "      <td>14574.150390</td>\n",
              "      <td>869500.0</td>\n",
              "      <td>14789.950200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1983 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Date          Open  ...    Volume         close\n",
              "0     21-01-2013   6085.750000  ...  130900.0   6082.299805\n",
              "1     22-01-2013   6080.149902  ...  129000.0   6048.500000\n",
              "2     23-01-2013   6052.850098  ...  137000.0   6054.299805\n",
              "3     24-01-2013   6046.200195  ...  185200.0   6019.350098\n",
              "4     25-01-2013   6024.500000  ...  147600.0   6074.649902\n",
              "...          ...           ...  ...       ...           ...\n",
              "1978  28-01-2021  13810.400390  ...  637900.0  13817.549810\n",
              "1979  29-01-2021  13946.599610  ...  753200.0  13634.599610\n",
              "1980  01-02-2021  13758.599610  ...  870500.0  14281.200200\n",
              "1981  02-02-2021  14481.099610  ...  915000.0  14647.849610\n",
              "1982  03-02-2021  14754.900390  ...  869500.0  14789.950200\n",
              "\n",
              "[1983 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUd3qLdohWd3",
        "outputId": "fef8d21e-8277-4475-fb5a-b657ea860a48"
      },
      "source": [
        "\n",
        "df = df.dropna()\n",
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Date      0\n",
              "Open      0\n",
              "High      0\n",
              "Low       0\n",
              "Volume    0\n",
              "close     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJwQY-vZNkvX",
        "outputId": "da8eab96-9c5a-4d94-c556-c6b105e8463a"
      },
      "source": [
        "cols=list(df)[1:]\r\n",
        "cols"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Open', 'High', 'Low', 'Volume', 'close']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7F_v049sOLKt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68b7bfb5-3431-4c4b-bde0-2b71905aca92"
      },
      "source": [
        "df_for_training = df[cols].astype(float)\r\n",
        "df_for_training.shape[1]\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7owQ3jnhOVAQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1891d535-a9e3-4c39-9837-b2e835c7e616"
      },
      "source": [
        "scaler = MinMaxScaler()\r\n",
        "scaler = scaler.fit(df_for_training)\r\n",
        "df_for_training_scaled = scaler.transform(df_for_training)\r\n",
        "df_for_training_scaled"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.08951365, 0.08131481, 0.10007614, 0.07228051, 0.08388259],\n",
              "       [0.0889255 , 0.08204244, 0.09747442, 0.07123136, 0.08032656],\n",
              "       [0.08605831, 0.07874441, 0.09542794, 0.07564881, 0.08093675],\n",
              "       ...,\n",
              "       [0.8953625 , 0.94424755, 0.90350382, 0.48067366, 0.94647526],\n",
              "       [0.97124379, 0.98564053, 0.98889512, 0.50524572, 0.98504983],\n",
              "       [1.        , 1.        , 1.        , 0.48012148, 1.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77w_s4F6OcOd"
      },
      "source": [
        "trainX = []\r\n",
        "trainY = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0zw92GIOe76"
      },
      "source": [
        "n_future = 1   # Number of days we want to predict into the future\r\n",
        "n_past = 100  # Number of past days we want to use to predict the future\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UemHyHT5Oieq"
      },
      "source": [
        "for i in range(n_past, len(df_for_training_scaled) - n_future +1):\r\n",
        "    trainX.append(df_for_training_scaled[i - n_past:i, 0:df_for_training.shape[1]])   #2nd argument is the index of columns used (0:df_for_training.shape[1])\r\n",
        "    trainY.append(df_for_training_scaled[i + n_future - 1:i + n_future, 4])\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByNrXcjHOmVq",
        "outputId": "6a247430-4601-43f9-ddb6-ac7f53056f58"
      },
      "source": [
        "trainX, trainY = np.array(trainX), np.array(trainY)\r\n",
        "\r\n",
        "print('trainX shape == {}.'.format(trainX.shape))\r\n",
        "print('trainY shape == {}.'.format(trainY.shape))\r\n",
        "print('TrainX=',trainX)\r\n",
        "print('TrainY=',trainY)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "trainX shape == (1867, 100, 5).\n",
            "trainY shape == (1867, 1).\n",
            "TrainX= [[[0.08951365 0.08131481 0.10007614 0.07228051 0.08388259]\n",
            "  [0.0889255  0.08204244 0.09747442 0.07123136 0.08032656]\n",
            "  [0.08605831 0.07874441 0.09542794 0.07564881 0.08093675]\n",
            "  ...\n",
            "  [0.05653549 0.04975314 0.06554525 0.07752623 0.04999502]\n",
            "  [0.04998187 0.04315186 0.05967552 0.07840972 0.04356678]\n",
            "  [0.05414091 0.05252768 0.06562984 0.06869133 0.05506603]]\n",
            "\n",
            " [[0.0889255  0.08204244 0.09747442 0.07123136 0.08032656]\n",
            "  [0.08605831 0.07874441 0.09542794 0.07564881 0.08093675]\n",
            "  [0.0853599  0.07827326 0.09402134 0.10226394 0.07725975]\n",
            "  ...\n",
            "  [0.04998187 0.04315186 0.05967552 0.07840972 0.04356678]\n",
            "  [0.05414091 0.05252768 0.06562984 0.06869133 0.05506603]\n",
            "  [0.06164499 0.05624451 0.06889257 0.05919382 0.05944795]]\n",
            "\n",
            " [[0.08605831 0.07874441 0.09542794 0.07564881 0.08093675]\n",
            "  [0.0853599  0.07827326 0.09402134 0.10226394 0.07725975]\n",
            "  [0.08308081 0.07986993 0.09471937 0.08150193 0.08307775]\n",
            "  ...\n",
            "  [0.05414091 0.05252768 0.06562984 0.06869133 0.05506603]\n",
            "  [0.06164499 0.05624451 0.06889257 0.05919382 0.05944795]\n",
            "  [0.06390305 0.05713445 0.0724937  0.06488128 0.05561314]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.66510352 0.65617757 0.67568455 0.33522916 0.6567578 ]\n",
            "  [0.64285903 0.64226297 0.65410935 0.37620099 0.63638941]\n",
            "  [0.64340508 0.63483984 0.64861505 0.30938708 0.63861984]\n",
            "  ...\n",
            "  [0.94570678 0.93394518 0.9318001  0.36482606 0.91347138]\n",
            "  [0.90080293 0.89837876 0.9089505  0.35223633 0.89769537]\n",
            "  [0.91510739 0.9055611  0.89662937 0.41590282 0.87844749]]\n",
            "\n",
            " [[0.64285903 0.64226297 0.65410935 0.37620099 0.63638941]\n",
            "  [0.64340508 0.63483984 0.64861505 0.30938708 0.63861984]\n",
            "  [0.64539534 0.64071344 0.65271328 0.31595803 0.63465347]\n",
            "  ...\n",
            "  [0.90080293 0.89837876 0.9089505  0.35223633 0.89769537]\n",
            "  [0.91510739 0.9055611  0.89662937 0.41590282 0.87844749]\n",
            "  [0.8953625  0.94424755 0.90350382 0.48067366 0.94647526]]\n",
            "\n",
            " [[0.64340508 0.63483984 0.64861505 0.30938708 0.63861984]\n",
            "  [0.64539534 0.64071344 0.65271328 0.31595803 0.63465347]\n",
            "  [0.62859641 0.62614979 0.64157669 0.40248482 0.63051356]\n",
            "  ...\n",
            "  [0.91510739 0.9055611  0.89662937 0.41590282 0.87844749]\n",
            "  [0.8953625  0.94424755 0.90350382 0.48067366 0.94647526]\n",
            "  [0.97124379 0.98564053 0.98889512 0.50524572 0.98504983]]]\n",
            "TrainY= [[0.05944795]\n",
            " [0.05561314]\n",
            " [0.05652318]\n",
            " ...\n",
            " [0.94647526]\n",
            " [0.98504983]\n",
            " [1.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLrtoZAjOsvo",
        "outputId": "ed6e06ee-6cab-4ff8-b485-d5f13da1fd62"
      },
      "source": [
        "model = Sequential()\r\n",
        "model.add(LSTM(50 ,input_shape=(trainX.shape[1], trainX.shape[2]), return_sequences=True))\r\n",
        "model.add(LSTM(100,return_sequences=True))\r\n",
        "model.add(LSTM(100,return_sequences=True))\r\n",
        "model.add(LSTM(100))\r\n",
        "model.add(Dense(trainY.shape[1]))\r\n",
        "\r\n",
        "model.compile(optimizer='adam', loss='mse')\r\n",
        "print(model.summary())\r\n",
        "history = model.fit(trainX, trainY, epochs=100, batch_size=64, validation_split=0.1, verbose=1)\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_4 (LSTM)                (None, 100, 50)           11200     \n",
            "_________________________________________________________________\n",
            "lstm_5 (LSTM)                (None, 100, 100)          60400     \n",
            "_________________________________________________________________\n",
            "lstm_6 (LSTM)                (None, 100, 100)          80400     \n",
            "_________________________________________________________________\n",
            "lstm_7 (LSTM)                (None, 100)               80400     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 232,501\n",
            "Trainable params: 232,501\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "27/27 [==============================] - 6s 77ms/step - loss: 0.0562 - val_loss: 0.0046\n",
            "Epoch 2/100\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0029 - val_loss: 0.0094\n",
            "Epoch 3/100\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0015 - val_loss: 0.0059\n",
            "Epoch 4/100\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0011 - val_loss: 0.0038\n",
            "Epoch 5/100\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0011 - val_loss: 0.0045\n",
            "Epoch 6/100\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.0010 - val_loss: 0.0027\n",
            "Epoch 7/100\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.0011 - val_loss: 0.0018\n",
            "Epoch 8/100\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 8.5113e-04 - val_loss: 0.0029\n",
            "Epoch 9/100\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 7.5502e-04 - val_loss: 0.0016\n",
            "Epoch 10/100\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 7.8114e-04 - val_loss: 0.0028\n",
            "Epoch 11/100\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 5.5083e-04 - val_loss: 0.0024\n",
            "Epoch 12/100\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 5.6367e-04 - val_loss: 0.0024\n",
            "Epoch 13/100\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 5.9539e-04 - val_loss: 0.0023\n",
            "Epoch 14/100\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 5.2196e-04 - val_loss: 0.0015\n",
            "Epoch 15/100\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 6.4046e-04 - val_loss: 0.0024\n",
            "Epoch 16/100\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 5.4641e-04 - val_loss: 0.0024\n",
            "Epoch 17/100\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 7.4729e-04 - val_loss: 0.0040\n",
            "Epoch 18/100\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 6.4762e-04 - val_loss: 0.0017\n",
            "Epoch 19/100\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 5.3805e-04 - val_loss: 0.0017\n",
            "Epoch 20/100\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 4.7693e-04 - val_loss: 0.0018\n",
            "Epoch 21/100\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 4.4102e-04 - val_loss: 0.0022\n",
            "Epoch 22/100\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 4.4523e-04 - val_loss: 0.0022\n",
            "Epoch 23/100\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 4.1652e-04 - val_loss: 0.0024\n",
            "Epoch 24/100\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 4.9624e-04 - val_loss: 0.0014\n",
            "Epoch 25/100\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 5.1521e-04 - val_loss: 0.0012\n",
            "Epoch 26/100\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 4.7220e-04 - val_loss: 0.0015\n",
            "Epoch 27/100\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 4.0611e-04 - val_loss: 0.0022\n",
            "Epoch 28/100\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 4.6252e-04 - val_loss: 0.0012\n",
            "Epoch 29/100\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 3.8032e-04 - val_loss: 0.0013\n",
            "Epoch 30/100\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 3.6984e-04 - val_loss: 0.0018\n",
            "Epoch 31/100\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 4.1786e-04 - val_loss: 0.0016\n",
            "Epoch 32/100\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 3.6638e-04 - val_loss: 0.0015\n",
            "Epoch 33/100\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 3.6905e-04 - val_loss: 0.0011\n",
            "Epoch 34/100\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 3.8077e-04 - val_loss: 0.0013\n",
            "Epoch 35/100\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 3.5902e-04 - val_loss: 0.0012\n",
            "Epoch 36/100\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 5.4229e-04 - val_loss: 0.0011\n",
            "Epoch 37/100\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 3.5535e-04 - val_loss: 0.0012\n",
            "Epoch 38/100\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 3.6572e-04 - val_loss: 0.0012\n",
            "Epoch 39/100\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 3.3697e-04 - val_loss: 0.0024\n",
            "Epoch 40/100\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 4.0860e-04 - val_loss: 0.0013\n",
            "Epoch 41/100\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 3.2519e-04 - val_loss: 0.0013\n",
            "Epoch 42/100\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 3.1340e-04 - val_loss: 0.0014\n",
            "Epoch 43/100\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 3.4199e-04 - val_loss: 0.0012\n",
            "Epoch 44/100\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 2.8932e-04 - val_loss: 0.0010\n",
            "Epoch 45/100\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 3.9580e-04 - val_loss: 0.0012\n",
            "Epoch 46/100\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 3.9327e-04 - val_loss: 0.0011\n",
            "Epoch 47/100\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 2.8882e-04 - val_loss: 0.0011\n",
            "Epoch 48/100\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 3.1700e-04 - val_loss: 0.0011\n",
            "Epoch 49/100\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 3.0842e-04 - val_loss: 9.8812e-04\n",
            "Epoch 50/100\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 3.5291e-04 - val_loss: 9.5525e-04\n",
            "Epoch 51/100\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 2.8502e-04 - val_loss: 0.0010\n",
            "Epoch 52/100\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 3.5298e-04 - val_loss: 9.3800e-04\n",
            "Epoch 53/100\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 2.8147e-04 - val_loss: 0.0011\n",
            "Epoch 54/100\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 2.7882e-04 - val_loss: 9.8565e-04\n",
            "Epoch 55/100\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 2.8478e-04 - val_loss: 0.0011\n",
            "Epoch 56/100\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 2.6058e-04 - val_loss: 0.0021\n",
            "Epoch 57/100\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 2.9156e-04 - val_loss: 7.6996e-04\n",
            "Epoch 58/100\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 3.1947e-04 - val_loss: 9.6654e-04\n",
            "Epoch 59/100\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 2.4013e-04 - val_loss: 0.0013\n",
            "Epoch 60/100\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 2.6558e-04 - val_loss: 7.9398e-04\n",
            "Epoch 61/100\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 3.0768e-04 - val_loss: 9.9678e-04\n",
            "Epoch 62/100\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 2.3969e-04 - val_loss: 8.6126e-04\n",
            "Epoch 63/100\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 3.3169e-04 - val_loss: 0.0023\n",
            "Epoch 64/100\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 2.7434e-04 - val_loss: 7.8784e-04\n",
            "Epoch 65/100\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 2.3312e-04 - val_loss: 0.0012\n",
            "Epoch 66/100\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 2.0822e-04 - val_loss: 7.0758e-04\n",
            "Epoch 67/100\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 2.1512e-04 - val_loss: 0.0010\n",
            "Epoch 68/100\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 2.3640e-04 - val_loss: 6.7695e-04\n",
            "Epoch 69/100\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 2.7091e-04 - val_loss: 6.1220e-04\n",
            "Epoch 70/100\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 2.2515e-04 - val_loss: 8.8631e-04\n",
            "Epoch 71/100\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 1.9399e-04 - val_loss: 6.9979e-04\n",
            "Epoch 72/100\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 2.4446e-04 - val_loss: 0.0011\n",
            "Epoch 73/100\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 1.8080e-04 - val_loss: 7.4975e-04\n",
            "Epoch 74/100\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 1.9489e-04 - val_loss: 5.3099e-04\n",
            "Epoch 75/100\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 1.7523e-04 - val_loss: 0.0013\n",
            "Epoch 76/100\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 2.9562e-04 - val_loss: 7.3399e-04\n",
            "Epoch 77/100\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 2.1727e-04 - val_loss: 6.2537e-04\n",
            "Epoch 78/100\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 1.7633e-04 - val_loss: 5.4137e-04\n",
            "Epoch 79/100\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 1.7458e-04 - val_loss: 5.4832e-04\n",
            "Epoch 80/100\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 2.3067e-04 - val_loss: 4.4141e-04\n",
            "Epoch 81/100\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 1.8220e-04 - val_loss: 5.6117e-04\n",
            "Epoch 82/100\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 1.8751e-04 - val_loss: 5.1913e-04\n",
            "Epoch 83/100\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 1.7945e-04 - val_loss: 9.8104e-04\n",
            "Epoch 84/100\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 1.8706e-04 - val_loss: 7.3543e-04\n",
            "Epoch 85/100\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 1.7004e-04 - val_loss: 3.9262e-04\n",
            "Epoch 86/100\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 1.8786e-04 - val_loss: 7.7115e-04\n",
            "Epoch 87/100\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 1.6033e-04 - val_loss: 4.0557e-04\n",
            "Epoch 88/100\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 1.6537e-04 - val_loss: 4.1606e-04\n",
            "Epoch 89/100\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 1.4197e-04 - val_loss: 0.0020\n",
            "Epoch 90/100\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 2.7266e-04 - val_loss: 5.9723e-04\n",
            "Epoch 91/100\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 1.4311e-04 - val_loss: 6.6567e-04\n",
            "Epoch 92/100\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 1.5289e-04 - val_loss: 4.5817e-04\n",
            "Epoch 93/100\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 2.4037e-04 - val_loss: 4.3809e-04\n",
            "Epoch 94/100\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 1.6519e-04 - val_loss: 0.0017\n",
            "Epoch 95/100\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 3.2159e-04 - val_loss: 5.3370e-04\n",
            "Epoch 96/100\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 1.4903e-04 - val_loss: 6.4350e-04\n",
            "Epoch 97/100\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 1.5697e-04 - val_loss: 0.0012\n",
            "Epoch 98/100\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 1.6595e-04 - val_loss: 4.3956e-04\n",
            "Epoch 99/100\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 1.7357e-04 - val_loss: 4.3266e-04\n",
            "Epoch 100/100\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 1.5501e-04 - val_loss: 4.3503e-04\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DwoGoGgGGf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "501f1f56-effe-49f6-a88a-78978d3e5c00"
      },
      "source": [
        "# Plot of the training and validation loss \n",
        "import matplotlib.pyplot as pyplot\n",
        "\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OleBXw3nO4Oi"
      },
      "source": [
        "#Forecasting...\r\n",
        "#Start with the last day in training date and predict future...\r\n",
        "n_future=1 #Redefining n_future to extend prediction dates beyond original n_future dates...\r\n",
        "forecast_period_dates = pd.date_range(list(train_dates)[-1], periods=n_future, freq='1d').tolist()\r\n",
        "\r\n",
        "forecast = model.predict(trainX[-n_future:]) #forecast "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "974SDeSIPB3Y"
      },
      "source": [
        "#Perform inverse transformation to rescale back to original range\r\n",
        "#Since we used 5 variables for transform, the inverse expects same dimensions\r\n",
        "#Therefore, let us copy our values 5 times and discard them after inverse transform\r\n",
        "forecast_copies = np.repeat(forecast, df_for_training.shape[1], axis=-1)\r\n",
        "y_pred_future = scaler.inverse_transform(forecast_copies)[:,0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4eE6l3gPOSP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3eeb9cf-432f-42fc-9780-7f4b3a1dc6eb"
      },
      "source": [
        "#Prediction for the next day\n",
        "y_pred_future = y_pred_future[::-1]\n",
        "y_pred_future"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([14367.856], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qq795YeDPIEs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbc5bbfb-03cf-416d-f8d8-396064c244a1"
      },
      "source": [
        "## %Difference in the predicted value\r\n",
        "prediction = y_pred_future[0]\r\n",
        "print('Predicted value for next day=',prediction)\r\n",
        "b = df['close'].iloc[-1]\r\n",
        "print('last close price=',b)\r\n",
        "percentage = ((prediction-b)/b)*100\r\n",
        "print('percentage change should be =', percentage.round(3),'%' )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted value for next day= 14367.856\n",
            "last close price= 14789.9502\n",
            "percentage change should be = -2.854 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEyxuJooPEpt"
      },
      "source": [
        "# Convert timestamp to date\r\n",
        "forecast_dates = []\r\n",
        "for time_i in forecast_period_dates:\r\n",
        "    forecast_dates.append(time_i.date())\r\n",
        "    \r\n",
        "df_forecast = pd.DataFrame({'Date':np.array(forecast_dates), 'Close':y_pred_future})\r\n",
        "df_forecast['Date']=pd.to_datetime(df_forecast['Date'])\r\n",
        "\r\n",
        "\r\n",
        "original = df[['Date', 'Close']]\r\n",
        "original['Date']=pd.to_datetime(original['Date'])\r\n",
        "original = original.loc[original['Date'] >= '2020-5-1']\r\n",
        "\r\n",
        "sns.lineplot(original['Date'], original['Close'])\r\n",
        "sns.lineplot(df_forecast['Date'], df_forecast['Close'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYa5x67s8UK4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}